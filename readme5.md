[Papers](#Papers)
- [2023](#2023)<br />

- [2022](#2022)<br />

- [2021](#2021)<br />

- [2020](#2020)<br />

- [2019](#2019)<br />

- [2018](#2018)<br />

- [2017](#2017)<br />

- [2016](#2016)<br />

### Papers
## 2023<br />

LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis <br />
[[Paper]](https://arxiv.org/abs/2301.04604)  [[Project]](https://zhujiapeng.github.io/linkgan/) [[Github]](https://github.com/zhujiapeng/linkgan) arxiv<br />
<sub><sup>Jiapeng Zhu, Ceyuan Yang, Yujun Shen, Zifan Shi, Deli Zhao, Qifeng Chen</sup></sub><br />
<details>
</details>

SLI-pSp: Injecting Multi-Scale Spatial Layout in pSp <br />
[[Paper]](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_SLI-pSp_Injecting_Multi-Scale_Spatial_Layout_in_pSp_WACV_2023_paper) WACV<br />
<sub><sup>Aradhya Neeraj Mathur, Anish Madan, Ojaswa Sharma</sup></sub><br />
<details>
</details>

## 2022<br />

Face Generation and Editing with StyleGAN: A Survey <br />
[[Paper]](https://arxiv.org/abs/2212.09102) arxiv<br />
<sub><sup>Andrew Melnik, Maksim Miasayedzenkau, Dzianis Makarovets, Dzianis Pirshtuk, Eren Akbulut, Dennis Holzmann, Tarek Renusch, Gustav Reichert, Helge Ritter</sup></sub><br />
<details>
</details>

3D Cartoon Face Generation with Controllable Expressions from a Single GAN Image <br />
[[Paper]](https://arxiv.org/abs/2207.14425) arxiv<br />
<sub><sup>Hao Wang, Guosheng Lin, Steven C. H. Hoi, Chunyan Miao</sup></sub><br />
<details>
</details>

Faces: AI Blitz XIII Solutions <br />
[[Paper]](https://arxiv.org/abs/2204.01081)  [[Github]](https://github.com/ndrwmlnk/ai-blitz-xiii) arxiv<br />
<sub><sup>Andrew Melnik, Eren Akbulut, Jannik Sheikh, Kira Loos, Michael Buettner, Tobias Lenze</sup></sub><br />
<details>
</details>

MyStyle: A Personalized Generative Prior <br />
[[Paper]](https://arxiv.org/abs/2203.17272) [[Github]](https://mystyle-personalized-prior.github.io/) [[Video]](https://www.youtube.com/watch?v=axWo_9Gt47o) arxiv<br />
<sub><sup>Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen-or</sup></sub><br />
<details>
</details>

Third Time's the Charm? Image and Video Editing with StyleGAN3 <br />
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/yuval-alaluf/stylegan3-editing) arxiv<br />
<sub><sup>Yuval Alaluf, Or Patashnik, Zongze Wu, Asif Zamir, Eli Shechtman, Dani Lischinski, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

E2Style: Improve the Efficiency and Effectiveness of StyleGAN Inversion <br />
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/wty-ustc/e2style) IEEE Transactions on Image Processing<br />
<sub><sup>Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Weiming Zhang, Lu Yuan, Gang Hua, Nenghai Yu</sup></sub><br />
<details>
</details>

Unsupervised face frontalization using disentangled representation-learning CycleGAN <br />
[[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S1077314222001096) Computer Vision and Image Understanding<br />
<sub><sup>Yanfei Liu Junhua Chen</sup></sub><br />
<details>
</details>

## 2021<br />

HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing <br />
[[Paper]](https://arxiv.org/abs/2111.15666) [[Github]](https://github.com/yuval-alaluf/hyperstyle) [[Video]](https://www.youtube.com/watch?v=_sbXmLY2jMw) CVPR<br />
<sub><sup>Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, Amit H. Bermano</sup></sub><br />
<details>
</details>

Fine-Tuning StyleGAN2 For Cartoon Face Generation <br />
[[Paper]](https://arxiv.org/abs/2106.12445) arxiv<br />
<sub><sup>Jihye Back</sup></sub><br />
<details>
</details>

Pivotal Tuning for Latent-based Editing of Real Images <br />
[[Paper]](https://arxiv.org/abs/2106.05744)  [[Github]](https://github.com/danielroich/PTI) ACM<br />
<sub><sup>Daniel Roich, Ron Mokady, Amit H. Bermano, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

Transforming the Latent Space of StyleGAN for Real Face Editing <br />
[[Paper]](https://arxiv.org/abs/2105.14230)  [[Github]](https://github.com/AnonSubm2021/TransStyleGAN) arxiv<br />
<sub><sup>Heyi Li, Jinlong Liu, Xinyu Zhang, Yunzhi Bai, Huayan Wang, Klaus Mueller</sup></sub><br />
<details>
</details>

One Shot Face Swapping on Megapixels <br />
[[Paper]](https://arxiv.org/abs/2105.04932)  [[Github]](https://github.com/zyainfal/One-Shot-Face-Swapping-on-Megapixels) CVPR<br />
<sub><sup>Yuhao Zhu, Qi Li, Jian Wang, Chengzhong Xu, Zhenan Sun</sup></sub><br />
<details>
</details>

ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement <br />
[[Paper]](https://arxiv.org/abs/2104.02699) [[Github]](https://github.com/yuval-alaluf/restyle-encoder) [[Video]](https://www.youtube.com/watch?v=6pGzLECSIWM) ICCV<br />
<sub><sup>Yuval Alaluf, Or Patashnik, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

Designing an Encoder for StyleGAN Image Manipulation <br />
[[Paper]](https://arxiv.org/abs/2102.02766) [[Github]](https://github.com/omertov/encoder4editing) [[Video]](https://dl.acm.org/doi/10.1145/3450626.3459838) arxiv<br />
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery <br />
[[Paper]](https://arxiv.org/abs/2103.17249) [[Github]](https://github.com/orpatashnik/StyleCLIP) [[Video]](https://www.youtube.com/watch?v=5icI0NgALnQ) IEEE/CVF<br />
<sub><sup>Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski</sup></sub><br />
<details>
</details>

StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators <br />
[[Paper]](https://arxiv.org/abs/2108.00946)  [[Github]](https://github.com/rinongal/StyleGAN-nada) CoRR<br />
<sub><sup>Rinon Gal, Or Patashnik, Haggai Maron, Gal Chechik, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

Alias-Free Generative Adversarial Networks <br />
[[Paper]](https://arxiv.org/abs/2106.12423) [[Github]](https://github.com/NVlabs/stylegan3) [[Video]](https://nvlabs-fi-cdn.nvidia.com/stylegan3/videos/) NeurIPS<br />
<sub><sup>Tero Karras, Miika Aittala, Samuli Laine, Erik HÃ¤rkÃ¶nen, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />
<details>
</details>

Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement <br />
[[Paper]](https://arxiv.org/abs/2106.11423)  [[Video]](https://www.youtube.com/watch?v=V9r_jOiGX84) IEEE/CVF<br />
<sub><sup>Huiwen Luo, Koki Nagano, Han-Wei Kung, Mclean Goldwhite, Qingguo Xu, Zejian Wang, Lingyu Wei, Liwen Hu, Hao Li</sup></sub><br />
<details>
</details>

Learning Transferable Visual Models From Natural Language Supervision <br />
[[Paper]](https://arxiv.org/abs/2103.00020)  [[Github]](https://github.com/openai/CLIP) PMLR<br />
<sub><sup>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever</sup></sub><br />
<details>
</details>

StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation <br />
[[Paper]](https://arxiv.org/abs/2107.04331) [[Github]](https://github.com/wonjongg/StyleCariGAN) [[Video]](https://www.youtube.com/watch?v=kpHbGOlI-BU&feature=youtu.be) ACM<br />
<sub><sup>Wonjong Jang, Gwangjin Ju, Yucheol Jung, Jiaolong Yang, Xin Tong, Seungyong Lee</sup></sub><br />
<details>
</details>

Towards Real-World Blind Face Restoration with Generative Facial Prior <br />
[[Paper]](https://arxiv.org/abs/2101.04061)  [[Github]](https://github.com/TencentARC/GFPGAN) IEEE/CVF<br />
<sub><sup>Xintao Wang, Yu Li, Honglun Zhang, Ying Shan</sup></sub><br />
<details>
</details>

Positional Encoding as Spatial Inductive Bias in GANs <br />
[[Paper]](https://arxiv.org/abs/2012.05217) IEEE/CVF 2021<br />
<sub><sup>Rui Xu, Xintao Wang, Kai Chen, Bolei Zhou, Chen Change Loy</sup></sub><br />
<details>
</details>

Designing an Encoder for StyleGAN Image Manipulation <br />
[[Paper]](https://arxiv.org/abs/2102.02766)  [[Github]](https://github.com/omertov/encoder4editing) ACM<br />
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation <br />
[[Paper]](https://arxiv.org/abs/2110.11728)  [[Github]](https://github.com/onion-liu/BlendGAN) Advances in Neural Information Processing Systems<br />
<sub><sup>Mingcong Liu, Qiang Li, Zekui Qin, Guoxin Zhang, Pengfei Wan, Wen Zheng</sup></sub><br />
<details>
</details>

StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation <br />
[[Paper]](https://arxiv.org/abs/2011.12799) [[Github]](https://github.com/betterze/StyleSpace) [[Video]](https://www.youtube.com/watch?v=U7qRotRGr1w&feature=youtu.be) CVPR<br />
<sub><sup>Zongze Wu, Dani Lischinski, Eli Shechtman</sup></sub><br />
<details>
</details>

## 2020<br />

Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation <br />
[[Paper]](https://arxiv.org/abs/2008.00951) [[Github]](https://github.com/eladrich/pixel2style2pixel) [[Video]](https://www.youtube.com/watch?v=bfvSwhqsTgM) CVPR<br />
<sub><sup>Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or</sup></sub><br />
<details>
</details>

Training Generative Adversarial Networks with Limited Data <br />
[[Paper]](https://arxiv.org/abs/2006.06676)  [[Github]](https://github.com/NVlabs/stylegan2-ada) arxiv<br />
<sub><sup>Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila</sup></sub><br />
<details>
</details>

The Creation and Detection of Deepfakes: A Survey <br />
[[Paper]](https://arxiv.org/abs/2004.11138) CSUR<br />
<sub><sup>Yisroel Mirsky, Wenke Lee</sup></sub><br />
<details>
</details>

StyleRig: Rigging StyleGAN for 3D Control over Portrait Images <br />
[[Paper]](https://arxiv.org/abs/2004.00121) IEEE/CVF<br />
<sub><sup>Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian Bernard, Hans-Peter Seidel, Patrick PÃ©rez, Michael ZollhÃ¶fer, Christian Theobalt</sup></sub><br />
<details>
</details>

Media Forensics and DeepFakes: an overview <br />
[[Paper]](https://arxiv.org/abs/2001.06564) IEEE Journal of Selected Topics in Signal Processing<br />
<sub><sup>Luisa Verdoliva</sup></sub><br />
<details>
</details>

Neural Head Reenactment with Latent Pose Descriptors <br />
[[Paper]](https://arxiv.org/abs/2004.12000)  [[Github]](https://github.com/shrubb/latent-pose-reenactment) CVPR<br />
<sub><sup>Egor Burkov, Igor Pasechnik, Artur Grigorev, Victor Lempitsky</sup></sub><br />
<details>
</details>

GAN Compression: Efficient Architectures for Interactive Conditional GANs <br />
[[Paper]](https://arxiv.org/abs/2003.08936) [[Github]](https://github.com/mit-han-lab/gan-compression) [[Video]](https://www.youtube.com/playlist?list=PL80kAHvQbh-r5R8UmXhQK1ndqRvPNw_ex) CVPR<br />
<sub><sup>Muyang Li, Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, Song Han</sup></sub><br />
<details>
</details>

StyleGAN2 Distillation for Feed-forward Image Manipulation <br />
[[Paper]](https://arxiv.org/abs/2003.03581)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) Springer<br />
<sub><sup>Yuri Viazovetskyi, Vladimir Ivashkin, Evgeny Kashin </sup></sub><br />
<details>
</details>

Collaborative Learning for Faster StyleGAN Embedding <br />
[[Paper]](https://arxiv.org/abs/2007.01758)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv<br />
<sub><sup>Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, Xiaokang Yang</sup></sub><br />
<details>
</details>

In-Domain GAN Inversion for Real Image Editing <br />
[[Paper]](https://arxiv.org/abs/2004.00049)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv<br />
<sub><sup>Jiapeng Zhu, Yujun Shen, Deli Zhao, Bolei Zhou</sup></sub><br />
<details>
</details>

Interpreting the Latent Space of GANs for Semantic Face Editing <br />
[[Paper]](https://arxiv.org/abs/1907.10786) CVPR<br />
<sub><sup>Yujun Shen, Jinjin Gu, Xiaoou Tang, Bolei Zhou</sup></sub><br />
<details>
</details>

GANSpace: Discovering Interpretable GAN Controls <br />
[[Paper]](https://arxiv.org/abs/2004.02546)  [[Github]](https://github.com/harskish/ganspace) Advances in Neural Information Processing Systems<br />
<sub><sup>Erik HÃ¤rkÃ¶nen, Aaron Hertzmann, Jaakko Lehtinen, Sylvain Paris</sup></sub><br />
<details>
</details>

Resolution Dependent GAN Interpolation for Controllable Image Synthesis Between Domains <br />
[[Paper]](https://arxiv.org/abs/2010.05334) arxiv<br />
<sub><sup>Justin N. M. Pinkney, Doron Adler</sup></sub><br />
<details>
</details>

Advancing High Fidelity Identity Swapping for Forgery Detection <br />
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Advancing_High_Fidelity_Identity_Swapping_for_Forgery_Detection_CVPR_2020_paper.html) CVPR<br />
<sub><sup>Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, Fang Wen</sup></sub><br />
<details>
</details>

## 2019<br />

Analyzing and Improving the Image Quality of StyleGAN <br />
[[Paper]](https://arxiv.org/abs/1912.04958) [[Github]](https://github.com/NVlabs/stylegan2) [[Video]](https://www.youtube.com/watch?v=c-NJtV9Jvp0) IEEE/CVF<br />
<sub><sup>Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />
<details>
</details>

Unconstrained Facial Expression Transfer using Style-based Generator <br />
[[Paper]](https://arxiv.org/abs/1912.06253) arxiv<br />
<sub><sup>Chao Yang, Ser-Nam Lim</sup></sub><br />
<details>
</details>

Image2StyleGAN++: How to Edit the Embedded Images? <br />
[[Paper]](https://arxiv.org/abs/1911.11544)  [[Video]](https://www.youtube.com/watch?v=kEKVSMTTQEI) IEEE/CVF<br />
<sub><sup>Rameen Abdal, Yipeng Qin, Peter Wonka</sup></sub><br />
<details>
</details>

Deep Learning for Deepfakes Creation and Detection: A Survey <br />
[[Paper]](https://arxiv.org/abs/1909.11573) arxiv<br />
<sub><sup>Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Duc Thanh Nguyen, Thien Huynh-The, Saeid Nahavandi, Thanh Tam Nguyen, Quoc-Viet Pham, Cuong M. Nguyen</sup></sub><br />
<details>
</details>

Mining Audio, Text and Visual Information for Talking Face Generation <br />
[[Paper]](https://ieeexplore.ieee.org/document/8970886) ICDM<br />
<sub><sup>L. Yu, J. Yu, and Q. Ling</sup></sub><br />
<details>
</details>

FReeNet: Multi-Identity Face Reenactment <br />
[[Paper]](https://arxiv.org/abs/1905.11805) arxiv<br />
<sub><sup>Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu, Yu Ding, Changjie Fan</sup></sub><br />
<details>
</details>

## 2018<br />

 A Style-Based Generator Architecture for Generative Adversarial Networks <br />
[[Paper]](https://arxiv.org/abs/1812.04948) [[Github]](https://github.com/NVlabs/stylegan) [[Video]](https://youtu.be/kSLJriaOumA) IEEE/CVF<br />
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />
<details>
</details>

Video-to-Video Synthesis <br />
[[Paper]](https://arxiv.org/abs/1808.06601) [[Github]](https://github.com/NVIDIA/vid2vid) [[Video]](https://www.youtube.com/watch?v=GrP_aOSXt5U) NeurIPS<br />
<sub><sup>Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin Liu, Andrew Tao, Jan Kautz, Bryan Catanzaro</sup></sub><br />
<details>
</details>

End-to-End Speech-Driven Facial Animation with Temporal GANs <br />
[[Paper]](https://arxiv.org/abs/1805.09313) BMVC<br />
<sub><sup>Konstantinos Vougioukas, Stavros Petridis, Maja Pantic </sup></sub><br />
<details>
</details>

Talking Face Generation by Conditional Recurrent Adversarial Network <br />
[[Paper]](https://arxiv.org/abs/1804.04786)  [[Github]](https://github.com/susanqq/Talking_Face_Generation) arxiv<br />
<sub><sup>Yang Song, Jingwen Zhu, Dawei Li, Xiaolong Wang, Hairong Qi</sup></sub><br />
<details>
</details>

Unsupervised Depth Estimation, 3D Face Rotation and Replacement <br />
[[Paper]](https://arxiv.org/abs/1803.09202)  [[Github]](https://github.com/joelmoniz/DepthNets) NeurIPS<br />
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />
<details>
</details>

ArcFace: Additive Angular Margin Loss for Deep Face Recognition <br />
[[Paper]](https://arxiv.org/abs/1801.07698)  [[Github]](https://github.com/deepinsight/insightface) IEEE/CVF<br />
<sub><sup>Jiankang Deng, Jia Guo, Jing Yang, Niannan Xue, Irene Kotsia, Stefanos Zafeiriou</sup></sub><br />
<details>
</details>

The Unreasonable Effectiveness of Deep Features as a Perceptual Metric <br />
[[Paper]](https://arxiv.org/abs/1801.03924)  [[Github]](https://github.com/richzhang/PerceptualSimilarity) CVPR<br />
<sub><sup>Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang</sup></sub><br />
<details>
</details>

Photorealistic Monocular Gaze Redirection Using Machine Learning <br />
[[Paper]](https://ieeexplore.ieee.org/document/8010348) IEEE<br />
<sub><sup>D. Kononenko, Y. Ganin, D. Sungatullina, and V. Lempitsky</sup></sub><br />
<details>
</details>

## 2017<br />

The Perception-Distortion Tradeoff <br />
[[Paper]](https://arxiv.org/abs/1711.06077) IEEE/CVPR<br />
<sub><sup>Yochai Blau, Tomer Michaeli</sup></sub><br />
<details>
</details>

Progressive Growing of GANs for Improved Quality, Stability, and Variation <br />
[[Paper]](https://arxiv.org/abs/1710.10196)  [[Github]](https://github.com/tkarras/progressive_growing_of_gans) ICLR<br />
<sub><sup>Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen</sup></sub><br />
<details>
</details>

MoCoGAN: Decomposing Motion and Content for Video Generation <br />
[[Paper]](https://arxiv.org/abs/1707.04993)  [[Github]](https://github.com/sergeytulyakov/mocogan) IEEE/CVF<br />
<sub><sup>Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz</sup></sub><br />
<details>
</details>

GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium <br />
[[Paper]](https://arxiv.org/abs/1706.08500)  [[Github]](https://github.com/bioinf-jku/TTUR) Advances in neural information processing systems<br />
<sub><sup>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter</sup></sub><br />
<details>
</details>

Representation Learning by Rotating Your Faces <br />
[[Paper]](https://arxiv.org/abs/1705.11136) IEEE Transactions on Pattern Analysis and Machine Intelligence<br />
<sub><sup>Luan Tran, Xi Yin, Xiaoming Liu</sup></sub><br />
<details>
</details>

On Convergence and Stability of GANs <br />
[[Paper]](https://arxiv.org/abs/1705.07215)  [[Github]](https://github.com/kodalinaveen3/DRAGAN) arxiv<br />
<sub><sup>Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira</sup></sub><br />
<details>
</details>

Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization <br />
[[Paper]](https://arxiv.org/abs/1703.06868)  [[Github]](https://github.com/xunhuang1995/AdaIN-style) ICCV<br />
<sub><sup>Xun Huang, Serge Belongie</sup></sub><br />
<details>
</details>

Precise Recovery of Latent Vectors from Generative Adversarial Networks <br />
[[Paper]](https://arxiv.org/abs/1702.04782) arxiv<br />
<sub><sup>Zachary C. Lipton, Subarna Tripathi</sup></sub><br />
<details>
</details>

Automated face swapping and its detection <br />
[[Paper]](https://ieeexplore.ieee.org/abstract/document/8124497) ICSIP<br />
<sub><sup>Y. Zhang, L. Zheng, and V. L. L. Thing</sup></sub><br />
<details>
</details>

Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks <br />
[[Paper]](https://arxiv.org/abs/1703.10593)  [[Github]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) CoRR<br />
<sub><sup>Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros</sup></sub><br />
<details>
</details>

## 2016<br />

Perceptual Losses for Real-Time Style Transfer and Super-Resolution <br />
[[Paper]](https://arxiv.org/abs/1603.08155) Springer<br />
<sub><sup>Justin Johnson, Alexandre Alahi, Li Fei-Fei</sup></sub><br />
<details>
</details>

 Face2Face: Real-time Face Capture and Reenactment of RGB Videos <br />
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Thies_Face2Face_Real-Time_Face_CVPR_2016_paper.html) IEEE conference on computer vision and pattern recognition<br />
<sub><sup>Justus Thies, Michael ZollhÃ¶fer, Marc Stamminger, Christian Theobalt, Matthias NieÃner</sup></sub><br />
<details>
</details>

